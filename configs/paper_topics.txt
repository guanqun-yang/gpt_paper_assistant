1. Methods for out-of-domain (OOD) generalization in text classification, especially hate speech classification. 
2. Methods to evaluate annotation quality in NLP datasets, especially hate speech datasets. 
3. Methods to improve the accuracy of hate speech detection. 
4. Methods to systematically generate test cases for NLP models; the proposed methods create test cases to challenge the NLP models to reveal their limitations. 
5. Methods to automatically select training datasets based on some guidelines; the carefully chosen data is beneficial to improve the performance on the end tasks like text classification. 
6. Empirical studies that show the limitations of NLP benchmarks, especially hate speech benchmarks.